% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read.R
\name{read}
\alias{read}
\title{Read ecocomDP data}
\usage{
read(
  id = NULL,
  path = NULL,
  parse.datetime = TRUE,
  globally.unique.keys = FALSE,
  site = "all",
  startdate = NA,
  enddate = NA,
  package = "basic",
  check.size = FALSE,
  nCores = 1,
  forceParallel = FALSE,
  token = NA,
  neon.data.save.dir = NULL,
  neon.data.read.path = NULL,
  ...,
  from.file = NULL
)
}
\arguments{
\item{id}{(character) Identifier of dataset to read. Identifiers are listed in the "id" column of the \code{search_data()} output. Older versions of ids listed in the "id" column of the \code{search_data()} output are supported, but a warning is issued.}

\item{path}{(character) Path to the directory in which the data will be read.}

\item{parse.datetime}{(logical) Attempt to parse datetime character strings through an algorithm. For EDI, the algorithm looks at the EML formatString value and calls \code{lubridate::parse_date_time()} with the appropriate \code{orders}. For NEON, the algorithm iterates through permutations of \code{ymd HMS} orders. Failed attempts will return a warning. Default is \code{TRUE}. No attempt is made at using time zones if included (these are dropped before parsing).}

\item{globally.unique.keys}{(logical) Whether to create globally unique primary keys (and associated
foreign keys). Reading multiple datasets raises the issue of referential 
integrity across datasets. If TRUE, \code{id} is appended to each 
table's primary key and associated foreign key. Defaults to FALSE.}

\item{site}{(character; NEON data only) A character vector of site codes to filter 
data on. Sites are listed in the "sites" column of the 
\code{search_data()} output. Defaults to "all", meaning all sites.}

\item{startdate}{(character; NEON data only) Start date to filter on in the form YYYY-MM. 
Defaults to NA, meaning all available dates.}

\item{enddate}{(character; NEON data only) End date to filter on in the form YYYY-MM. 
Defaults to NA, meaning all available dates.}

\item{package}{(character; NEON data only) Either 'basic' or 'expanded', indicating 
which data package to download. Defaults to basic.}

\item{check.size}{(logical; NEON data only) Should the user approve the total file size 
before downloading? Defaults to FALSE.}

\item{nCores}{(integer; NEON data only) The number of cores to parallelize the 
stacking procedure. Defaults to 1.}

\item{forceParallel}{(logical; NEON data only) If the data volume to be processed does not 
meet minimum requirements to run in parallel, this overrides. Defaults 
to FALSE.}

\item{token}{(character; NEON data only) User specific API token (generated within 
neon.datascience user accounts)}

\item{neon.data.save.dir}{(character; NEON data only) A character string that indicates the directory where NEON source data should be saved upon download from the NEON API. Data are downloaded using neonUtilities::loadByProduct() and saved in this directory as an RDS file. The filename will follow the format <NEON data product ID>_<timestamp>.RDS}

\item{neon.data.read.path}{(character; NEON data only) Path to read in an RDS file of 'stacked NEON data' from neonUtilities::loadByProduct()}

\item{...}{(NEON data only) Other arguments to \code{neonUtilities::loadByProduct()}}

\item{from.file}{(character) Full path to file to be read if .rds, or path to directory if .csv. Supported options are returned by \code{save_data()}}
}
\value{
(list) with the structure: 
    \itemize{
      \item{id - Dataset id}
        \itemize{
          \item metadata - List of info about the dataset. NOTE: This object is underdevelopment and content may change in future releases.
          \item tables - List of dataset tables as data.frames.
          \item validation_issues - List of validation issues. If the dataset fails any validation checks, 
    then descriptions of each issue are listed here.
      }
    }
}
\description{
Read ecocomDP data
}
\details{
Validation checks are applied to each dataset ensuring they comply with 
    the ecocomDP. A warning is issued when any validation check fails 
    (please report these to \url{https://github.com/EDIorg/ecocomDP/issues}). 
    All datasets are returned, even if they fail validation.
    
    Column classes are coerced to those defined in the ecocomDP 
    specification.
    
    Validation happens each time files are read, from source APIs or local environments.
    
    Details for read() function regarding NEON data: Using this function to read data with an \code{id} that begins with "neon.ecocomdp" will result in a query to download NEON data from the NEON Data Portal API using \code{neonUtilities::loadByProduct()}. If a query includes provisional data (or if you are not sure if the query includes provisional data), we recommend saving a copy of the data in the original format provided by NEON in addition to the derived ecocomDP data package. To do this, provide a directory path using the \code{neon.data.read.path} argument. For example, the query \code{my_ecocomdp_data <- read(id = "neon.ecocomdp.10022.001.001", neon.data.save.dir = "my_neon_data")} will download the data for NEON Data Product ID DP1.10022.001 (ground beetles in pitfall traps) and convert it to the ecocomDP data model. In doing so, a copy of the original NEON download will be saved in the directory "my_ neon_data with the filename "DP1.10022.001_<timestamp>.RDS" and the derived data package in the ecocomDP format will be stored in your R environment in an object named "my_ecocomdp_data". Further, if you wish to reload a previously downloaded NEON dataset into the ecocomDP format, you can do so using \code{my_ecocomdp_data <- read(id = "neon.ecocomdp.10022.001.001", neon.data.read.path = "my_neon_data/DP1.10022.001_<timestamp>.RDS")}
    
    Provisional NEON data. Despite NEON's controlled data entry, at times, errors are found in published data; for example, an analytical lab may adjust its calibration curve and re-calculate past analyses, or field scientists may discover a past misidentification. In these cases, Level 0 data are edited and the data are re-processed to Level 1 and re-published. Published data files include a time stamp in the file name; a new time stamp indicates data have been re-published and may contain differences from previously published data. Data are subject to re-processing at any time during an initial provisional period; data releases are never re-processed. All records downloaded from the NEON API will have a "release" field. For any provisional record, the value of this field will be "PROVISIONAL", otherwise, this field will have a value indicating the version of the release to which the record belongs. More details can be found at https://www.neonscience.org/data-samples/data-management/data-revisions-releases.
}
\note{
This function may not work between 01:00 - 03:00 UTC due to regular maintenance of the EDI Data Repository. If you have reached this warning outside these hours then there may be an unexpected issue that will be resolved shortly. Please try again later.

DESCRIBE WHAT PROVISIONAL NEON DATA IS, HOW TO IDENTIFIY IT IN THE RETURN FROM read().
}
\examples{
\dontrun{
# Read from EDI
dataset <- read("edi.193.3")

# Read from NEON
dataset <- read("neon.ecocomdp.20166.001.001")

# Read from NEON with filters
dataset <- read(
  id = "neon.ecocomdp.20166.001.001", 
  site = c("MAYF", "PRIN"),
  startdate = "2016-01", 
  enddate = "2018-11",
  check.size = FALSE)

# Read from local .rds
dataset <- read(from.file = "/Users/me/documents/data/dataset.rds")

# Read from local .csv
dataset <- read(from.file = "/Users/me/documents/data/dataset")

# Return datetimes as character
dataset <- read("edi.193.3", parse.datetime = FALSE)

# Read multiple datasets into list
datasets <- c(
  read("edi.193.3"),
  read("edi.262.1"),
  read("neon.ecocomdp.20166.001.001"))
}

}
