% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_data.R
\name{read_data}
\alias{read_data}
\title{Read ecocomDP data}
\usage{
read_data(
  id = NULL,
  path = NULL,
  parse.datetime = TRUE,
  globally.unique.keys = FALSE,
  site = "all",
  startdate = NA,
  enddate = NA,
  package = "basic",
  check.size = FALSE,
  nCores = 1,
  forceParallel = FALSE,
  token = NA,
  ...,
  from.file = NULL
)
}
\arguments{
\item{id}{(character) Identifier of dataset to read. Identifiers are listed in the "id" column of the \code{search_data()} output. Older versions of ids listed in the "id" column of the \code{search_data()} output are supported, but a warning is issued.}

\item{path}{(character) Path to the directory in which the data will be read.}

\item{parse.datetime}{(logical) Attempt to parse datetime character strings through an algorithm. For EDI, the algorithm looks at the EML formatString value and calls \code{lubridate::parse_date_time()} with the appropriate \code{orders}. For NEON, the algorithm iterates through permutations of \code{ymd HMS} orders. Failed attempts will return a warning. Default is \code{TRUE}. No attempt is made at using time zones if included (these are dropped before parsing).}

\item{globally.unique.keys}{(logical) Whether to create globally unique primary keys (and associated
foreign keys). Reading multiple datasets raises the issue of referential 
integrity across datasets. If TRUE, \code{id} is appended to each 
table's primary key and associated foreign key. Defaults to FALSE.}

\item{site}{(character; NEON data only) A character vector of site codes to filter 
data on. Sites are listed in the "sites" column of the 
\code{search_data()} output. Defaults to "all", meaning all sites.}

\item{startdate}{(character; NEON data only) Start date to filter on in the form YYYY-MM. 
Defaults to NA, meaning all available dates.}

\item{enddate}{(character; NEON data only) End date to filter on in the form YYYY-MM. 
Defaults to NA, meaning all available dates.}

\item{package}{(character; NEON data only) Either 'basic' or 'expanded', indicating 
which data package to download. Defaults to basic.}

\item{check.size}{(logical; NEON data only) Should the user approve the total file size 
before downloading? Defaults to FALSE.}

\item{nCores}{(integer; NEON data only) The number of cores to parallelize the 
stacking procedure. Defaults to 1.}

\item{forceParallel}{(logical; NEON data only) If the data volume to be processed does not 
meet minimum requirements to run in parallel, this overrides. Defaults 
to FALSE.}

\item{token}{(character; NEON data only) User specific API token (generated within 
neon.datascience user accounts)}

\item{...}{(NEON data only) Other arguments to \code{neonUtilities::loadByProduct()}}

\item{from.file}{(character) Full path to file to be read if .rds, or path to directory if .csv. Supported options are returned by \code{save_data()}}
}
\value{
(list) with the structure: 
    \itemize{
      \item{id - Dataset id}
        \itemize{
          \item metadata - Info about the dataset. NOTE: This object is underdevelopment and content may change in future releases
          \item tables - Dataset tables
          \item validation_issues - If the dataset fails any validation checks, 
    then they are listed here as a vector of character strings describing 
    each issue.
      }
    }
}
\description{
Read ecocomDP data
}
\details{
Validation checks are applied to each dataset ensuring they comply with 
    the ecocomDP. A warning is issued when any validation check fails 
    (please report these to \url{https://github.com/EDIorg/ecocomDP/issues}). 
    All datasets are returned, even if they fail validation.
    
    Column classes are coerced to those defined in the ecocomDP 
    specification.
    
    Validation happens each time files are read, from source APIs or local environments.
}
\note{
ADD MAINTENANCE TIMES OF EDI AND NEON SO USERS KNOW WHEN NOT TO EXPECT DATA ACCESS. ALSO ADD ERROR INCLUDING THIS INFO SO MADE AWARE WHEN ISSUE ARISES.
}
\examples{
\dontrun{
# Read from EDI
dataset <- read_data("edi.193.3")

# Read from NEON
dataset <- read_data("neon.ecocomdp.20166.001.001")

# Read from NEON with filters
dataset <- read_data(
  id = "neon.ecocomdp.20166.001.001", 
  site = c("MAYF", "PRIN"),
  startdate = "2016-01", 
  enddate = "2018-11",
  check.size = FALSE)

# Read from local .rds
dataset <- read_data(from.file = "/Users/me/documents/data/dataset.rds")

# Read from local .csv
dataset <- read_data(from.file = "/Users/me/documents/data/dataset")

# Return datetimes as character
dataset <- read_data("edi.193.3", parse.datetime = FALSE)

# Read multiple datasets into list
datasets <- c(
  read_data("edi.193.3"),
  read_data("edi.262.1"),
  read_data("neon.ecocomdp.20166.001.001"))
}

}
